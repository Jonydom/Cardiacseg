{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import torch\n",
    "import sys\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "import SimpleITK as sitk\n",
    "\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    CropForegroundd,\n",
    "    EnsureTyped,\n",
    "    EnsureType\n",
    ")\n",
    "from monai.data import CacheDataset, DataLoader, decollate_batch\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.metrics import DiceMetric\n",
    "from dataset import CHD2CHD\n",
    "from networks.cardiacseg import CardiacSeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:   0%|          | 0/22 [00:00<?, ?it/s]Modifying image pixdim from [0.75 0.75 1.25 1.  ] to [ 0.75        0.75        1.25       97.59146351]\n",
      "Modifying image pixdim from [0.75 0.75 1.25 1.  ] to [ 0.75        0.75        1.25       95.50278137]\n",
      "Modifying image pixdim from [0.75 0.75 1.25 1.  ] to [ 0.75        0.75        1.25       93.13716364]\n",
      "Modifying image pixdim from [0.75 0.75 1.25 1.  ] to [ 0.75        0.75        1.25       94.99958881]\n",
      "Loading dataset:  27%|██▋       | 6/22 [00:53<01:56,  7.31s/it]Modifying image pixdim from [0.75 0.75 1.25 1.  ] to [ 0.75        0.75        1.25       94.06962182]\n",
      "Loading dataset: 100%|██████████| 22/22 [03:20<00:00,  9.10s/it]\n"
     ]
    }
   ],
   "source": [
    "transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        Spacingd(keys=[\"image\", \"label\"], pixdim=(1, 1, 1), mode=(\"bilinear\", \"nearest\")),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"], a_min=500, a_max=2000,\n",
    "            b_min=0.0, b_max=1.0, clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        CHD2CHD(),\n",
    "\t    EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "    ])\n",
    "\n",
    "chd_dir = '/ImageCHD'\n",
    "val_images = sorted(glob.glob(f'{chd_dir}/test/images/*image.nii.gz'))\n",
    "val_labels = sorted(glob.glob(f'{chd_dir}/test/labels/*label.nii.gz'))\n",
    "test_files = [\n",
    "    {\"image\": image_name, \"label\": label_name}\n",
    "    for image_name, label_name in zip(val_images, val_labels)\n",
    "]\n",
    "print(len(test_files))\n",
    "\n",
    "# test_files\n",
    "test_ds = CacheDataset(data=test_files, transform=transforms, cache_rate=1.0, num_workers=4,)\n",
    "test_loader = DataLoader(test_ds, batch_size=1, num_workers=4,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_size = (128,128,128)\n",
    "num_classes = 1+7\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.arch = 'vit_base'\n",
    "        self.finetune = False\n",
    "args = Args()\n",
    "\n",
    "def vit_params(args):\n",
    "    if args.arch == 'vit_tiny':\n",
    "        hidden_size = 192\n",
    "        num_heads = 3\n",
    "    elif args.arch == 'vit_base':\n",
    "        hidden_size = 768\n",
    "        num_heads = 12\n",
    "    elif args.arch == 'vit_large':\n",
    "        hidden_size = 1152\n",
    "        num_heads = 16\n",
    "    elif args.arch == 'vit_huge':\n",
    "        hidden_size = 1344\n",
    "        num_heads = 16\n",
    "    return hidden_size, num_heads\n",
    "\n",
    "hidden_size, num_heads = vit_params(args)\n",
    "\n",
    "cardiacseg = CardiacSeg(\n",
    "                    in_channels = 1,\n",
    "                    out_channels = num_classes,\n",
    "                    img_size = feature_size,\n",
    "                    feature_size = 16,\n",
    "                    hidden_size = hidden_size,\n",
    "                    mlp_dim = 3072,\n",
    "                    num_heads = num_heads,\n",
    "                    norm_name = \"batch\",\n",
    "                    res_block = True,\n",
    "                    dropout_rate = 0.0,\n",
    "                    lora = False,\n",
    "                    res_adpter = False,\n",
    "                    adapterformer = False,\n",
    "                    args = args\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view(val_data, val_outputs, step=8):\n",
    "    img1, lab1 = (val_data[\"image\"][0][0], val_data[\"label\"][0][0])\n",
    "    lab2 = torch.argmax(val_outputs, dim=1).detach().cpu()[0]\n",
    "    for i in range(0, lab1.shape[-1], step):\n",
    "        a = img1[..., i]\n",
    "        b = lab1[..., i]\n",
    "        d = lab2[..., i]\n",
    "        if b.sum()+d.sum() > 0:\n",
    "            fig, ax = plt.subplots(1, 3, figsize=(9,3))\n",
    "            ax[0].set_title('raw image')\n",
    "            ax[0].imshow(a, cmap='gray')\n",
    "            ax[1].set_title('ground truth')\n",
    "            ax[1].imshow(a, cmap='gray')\n",
    "            ax[1].imshow(b, alpha=0.5, cmap='hot')\n",
    "            ax[2].set_title('pred label')\n",
    "            ax[2].imshow(a, cmap='gray')\n",
    "            ax[2].imshow(d, alpha=0.5, cmap='hot')\n",
    "            plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_pred = Compose([EnsureType(), AsDiscrete(argmax=True, to_onehot=num_classes)])\n",
    "post_label = Compose([EnsureType(), AsDiscrete(to_onehot=num_classes)])\n",
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
    "def test_step(model, test_loader):        \n",
    "    with torch.no_grad():\n",
    "        dice_list = np.empty((len(test_loader), num_classes))\n",
    "        i = 0\n",
    "        for test_data in test_loader:\n",
    "            i += 1\n",
    "            test_inputs, test_labels = (\n",
    "                test_data[\"image\"].to(device),\n",
    "                test_data[\"label\"].to(device),\n",
    "            )\n",
    "\n",
    "            roi_size = feature_size\n",
    "            sw_batch_size = 4\n",
    "            test_outputs = sliding_window_inference(test_inputs, roi_size, sw_batch_size, model)\n",
    "            view(test_data, test_outputs, step=20)\n",
    "\n",
    "            outputs = [post_pred(i) for i in decollate_batch(test_outputs)]\n",
    "            labels = [post_label(i) for i in decollate_batch(test_labels)]\n",
    "            dice = dice_metric(y_pred=outputs, y=labels).squeeze().cpu().numpy()\n",
    "            dice_avg = np.nanmean(dice)\n",
    "            dice_list[i-1] = np.append(dice, dice_avg)\n",
    "\n",
    "        dice_metric.reset()\n",
    "        print(f'average dice {np.mean(dice_list[:,-1])}, standard variation {np.std(dice_list[:,-1])}')\n",
    "        for i in range(num_classes-1):\n",
    "            print(f'class {i+1}, average dice {np.nanmean(dice_list[:,i])}, standard variation {np.nanstd(dice_list[:,i])}')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average dice 0.8918075344779275, standard variation 0.03304845323981812\n",
      "class 1, average dice 0.9259832934899763, standard variation 0.030582116635415952\n",
      "class 2, average dice 0.876049055294557, standard variation 0.05941473922174186\n",
      "class 3, average dice 0.916997644034299, standard variation 0.021506057010733975\n",
      "class 4, average dice 0.9121511280536652, standard variation 0.023933803539267665\n",
      "class 5, average dice 0.8861239463090896, standard variation 0.05455964147421084\n",
      "class 6, average dice 0.8876700618050315, standard variation 0.058084500745306474\n",
      "class 7, average dice 0.8392996219071475, standard variation 0.09825686648075699\n"
     ]
    }
   ],
   "source": [
    "weight_path = ''\n",
    "model = cardiacseg.to(device)  ####\n",
    "checkpoint = torch.load(weight_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "test_step(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c45886b2ec3b53825dd6b56a67a15422df6b72d20b00748a943189e6a8f5fbc7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
