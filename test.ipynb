{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jianglei/.conda/envs/chd/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import torch\n",
    "import sys\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "import SimpleITK as sitk\n",
    "import scipy.ndimage as ndimage\n",
    "\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    CropForegroundd,\n",
    "    EnsureTyped,\n",
    "    EnsureType\n",
    ")\n",
    "from monai.data import CacheDataset, DataLoader, decollate_batch\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.metrics import DiceMetric\n",
    "from dataset import CHD2CHD\n",
    "from networks.cardiacseg import CardiacSeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 34/34 [00:33<00:00,  1.00it/s]\n"
     ]
    }
   ],
   "source": [
    "transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        Spacingd(keys=[\"image\", \"label\"], pixdim=(1, 1, 1), mode=(\"bilinear\", \"nearest\")),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"], a_min=500, a_max=2000,\n",
    "            b_min=0.0, b_max=1.0, clip=True,\n",
    "        ),\n",
    "        # CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        CHD2CHD(),\n",
    "\t    EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "    ])\n",
    "\n",
    "chd_dir = '/home/jianglei/VCL-Project/data/2022Jianglei/dataset/ImageCHD_split_sdf'\n",
    "val_images = sorted(glob.glob(f'{chd_dir}/test/images/*image.nii.gz'))\n",
    "val_labels = sorted(glob.glob(f'{chd_dir}/test/labels/*label.nii.gz'))\n",
    "test_files = [\n",
    "    {\"image\": image_name, \"label\": label_name}\n",
    "    for image_name, label_name in zip(val_images, val_labels)\n",
    "]\n",
    "print(len(test_files))\n",
    "\n",
    "# test_files\n",
    "test_ds = CacheDataset(data=test_files, transform=transforms, cache_rate=1.0, num_workers=4,)\n",
    "test_loader = DataLoader(test_ds, batch_size=1, num_workers=4,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_size = (128,128,128)\n",
    "num_classes = 1+7\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.arch = 'vit_base'\n",
    "        self.finetune = False\n",
    "args = Args()\n",
    "\n",
    "def vit_params(args):\n",
    "    if args.arch == 'vit_tiny':\n",
    "        hidden_size = 192\n",
    "        num_heads = 3\n",
    "    elif args.arch == 'vit_base':\n",
    "        hidden_size = 768\n",
    "        num_heads = 12\n",
    "    elif args.arch == 'vit_large':\n",
    "        hidden_size = 1152\n",
    "        num_heads = 16\n",
    "    elif args.arch == 'vit_huge':\n",
    "        hidden_size = 1344\n",
    "        num_heads = 16\n",
    "    return hidden_size, num_heads\n",
    "\n",
    "hidden_size, num_heads = vit_params(args)\n",
    "\n",
    "cardiacseg = CardiacSeg(in_channels = 1,\n",
    "                            out_channels = num_classes,\n",
    "                            img_size = feature_size,\n",
    "                            feature_size = 16,    ####\n",
    "                            hidden_size = hidden_size,\n",
    "                            mlp_dim = 3072,\n",
    "                            num_heads = num_heads,\n",
    "                            pos_embed = \"conv\",\n",
    "                            norm_name = 'instance',\n",
    "                            conv_block = True,\n",
    "                            res_block = True,\n",
    "                            dropout_rate = 0.0,\n",
    "                            spatial_dims = 3,\n",
    "                            args = args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view(val_data, val_outputs, step=8):\n",
    "    img1, lab1 = (val_data[\"image\"][0][0], val_data[\"label\"][0][0])\n",
    "    lab2 = torch.argmax(val_outputs, dim=1).detach().cpu()[0]\n",
    "    for i in range(0, lab1.shape[-1], step):\n",
    "        a = img1[..., i]\n",
    "        b = lab1[..., i]\n",
    "        d = lab2[..., i]\n",
    "        if b.sum()+d.sum() > 0:\n",
    "            fig, ax = plt.subplots(1, 3, figsize=(9,3))\n",
    "            ax[0].set_title('raw image')\n",
    "            ax[0].imshow(a, cmap='gray')\n",
    "            ax[1].set_title('ground truth')\n",
    "            ax[1].imshow(a, cmap='gray')\n",
    "            ax[1].imshow(b, alpha=0.5, cmap='hot')\n",
    "            ax[2].set_title('pred label')\n",
    "            ax[2].imshow(a, cmap='gray')\n",
    "            ax[2].imshow(d, alpha=0.5, cmap='hot')\n",
    "            plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_pred = Compose([EnsureType(), AsDiscrete(argmax=True, to_onehot=num_classes)])\n",
    "post_label = Compose([EnsureType(), AsDiscrete(to_onehot=num_classes)])\n",
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
    "def test_step(model, test_loader, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    with torch.no_grad():\n",
    "        dice_list = np.empty((len(test_loader), num_classes))\n",
    "        i = 0\n",
    "        for test_data in test_loader:\n",
    "            test_inputs, test_labels = (\n",
    "                test_data[\"image\"].to(device),\n",
    "                test_data[\"label\"].to(device),\n",
    "            )\n",
    "\n",
    "            roi_size = feature_size\n",
    "            sw_batch_size = 4\n",
    "            test_outputs = sliding_window_inference(test_inputs, roi_size, sw_batch_size, model)\n",
    "            # view(test_data, test_outputs, step=20)\n",
    "            save_result(i, test_files, test_outputs, output_dir)\n",
    "            i += 1\n",
    "\n",
    "            outputs = [post_pred(i) for i in decollate_batch(test_outputs)]\n",
    "            labels = [post_label(i) for i in decollate_batch(test_labels)]\n",
    "            dice = dice_metric(y_pred=outputs, y=labels).squeeze().cpu().numpy()\n",
    "            dice_avg = np.nanmean(dice)\n",
    "            dice_list[i-1] = np.append(dice, dice_avg)\n",
    "\n",
    "        dice_metric.reset()\n",
    "        print(f'average dice {np.mean(dice_list[:,-1])}, standard variation {np.std(dice_list[:,-1])}')\n",
    "        for i in range(num_classes-1):\n",
    "            print(f'class {i+1}, average dice {np.nanmean(dice_list[:,i])}, standard variation {np.nanstd(dice_list[:,i])}')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result(n, files, val_outputs, output_dir):\n",
    "    val_outputs = torch.softmax(val_outputs, 1).cpu().numpy()\n",
    "    val_outputs = np.argmax(val_outputs, axis=1).astype(np.uint8)[0]\n",
    "\n",
    "    raw_img_p = files[n]['image']\n",
    "    raw_name = raw_img_p.split('/')[-1]\n",
    "    save_name = raw_name.replace('image.nii.gz', 'predlabel.nii.gz')\n",
    "    \n",
    "    raw_img = sitk.ReadImage(raw_img_p)\n",
    "    raw_img_arr = sitk.GetArrayFromImage(raw_img)\n",
    "    raw_size = raw_img_arr.shape\n",
    "    pred_shape = val_outputs.shape\n",
    "    \n",
    "    zoom = (raw_size[2]/pred_shape[0], raw_size[1]/pred_shape[1], raw_size[0]/pred_shape[2])\n",
    "    pred_arr = ndimage.zoom(val_outputs, zoom, output=np.uint8, order=0, mode='nearest', prefilter=False)\n",
    "    pred_arr = pred_arr.transpose(2,1,0)\n",
    "#     pred_arr = np.flip(pred_arr, 2)\n",
    "\n",
    "    out = sitk.GetImageFromArray(pred_arr)\n",
    "    out.SetDirection(raw_img.GetDirection())\n",
    "    out.SetOrigin(raw_img.GetOrigin())\n",
    "    out.SetSpacing(raw_img.GetSpacing())\n",
    "    save_pred = f'{output_dir}/{save_name}'\n",
    "    sitk.WriteImage(out, save_pred)\n",
    "    print('Done: {}'.format(raw_name))\n",
    "            \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: ct_1002_image.nii.gz\n",
      "Done: ct_1003_image.nii.gz\n",
      "Done: ct_1004_image.nii.gz\n",
      "Done: ct_1005_image.nii.gz\n",
      "Done: ct_1010_image.nii.gz\n",
      "Done: ct_1011_image.nii.gz\n",
      "Done: ct_1014_image.nii.gz\n",
      "Done: ct_1016_image.nii.gz\n",
      "Done: ct_1023_image.nii.gz\n",
      "Done: ct_1028_image.nii.gz\n",
      "Done: ct_1030_image.nii.gz\n",
      "Done: ct_1033_image.nii.gz\n",
      "Done: ct_1035_image.nii.gz\n",
      "Done: ct_1036_image.nii.gz\n",
      "Done: ct_1043_image.nii.gz\n",
      "Done: ct_1044_image.nii.gz\n",
      "Done: ct_1046_image.nii.gz\n",
      "Done: ct_1048_image.nii.gz\n",
      "Done: ct_1050_image.nii.gz\n",
      "Done: ct_1054_image.nii.gz\n",
      "Done: ct_1059_image.nii.gz\n",
      "Done: ct_1060_image.nii.gz\n",
      "Done: ct_1063_image.nii.gz\n",
      "Done: ct_1064_image.nii.gz\n",
      "Done: ct_1070_image.nii.gz\n",
      "Done: ct_1083_image.nii.gz\n",
      "Done: ct_1092_image.nii.gz\n",
      "Done: ct_1105_image.nii.gz\n",
      "Done: ct_1112_image.nii.gz\n",
      "Done: ct_1114_image.nii.gz\n",
      "Done: ct_1119_image.nii.gz\n",
      "Done: ct_1135_image.nii.gz\n",
      "Done: ct_1138_image.nii.gz\n",
      "Done: ct_1150_image.nii.gz\n",
      "average dice 0.8014564803735245, standard variation 0.1590832348871658\n",
      "class 1, average dice 0.8349514182876138, standard variation 0.19207484744141498\n",
      "class 2, average dice 0.7935002490001566, standard variation 0.1786878616126709\n",
      "class 3, average dice 0.82293219426099, standard variation 0.158278290019561\n",
      "class 4, average dice 0.8425140819128822, standard variation 0.1699810126683569\n",
      "class 5, average dice 0.8518957921436855, standard variation 0.08482315521649776\n",
      "class 6, average dice 0.7854556844514959, standard variation 0.1888360926910133\n",
      "class 7, average dice 0.7048498218699772, standard variation 0.1936287466787582\n"
     ]
    }
   ],
   "source": [
    "weight_path = '/home/jianglei/VCL-Project/data/2022Jianglei/CardiacSeg/output-sdf-b1in-cardiacseg/metric_model-epoch490-dice0.8008242249488831.pth'\n",
    "output_dir = \"/home/jianglei/VCL-Project/data/2022Jianglei/CardiacSeg/output-sdf-b1in-cardiacseg/output\"\n",
    "model = cardiacseg.to(device)  ####\n",
    "model = torch.nn.DataParallel(model)\n",
    "checkpoint = torch.load(weight_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'], strict=True)\n",
    "model.eval()\n",
    "test_step(model, test_loader, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "c45886b2ec3b53825dd6b56a67a15422df6b72d20b00748a943189e6a8f5fbc7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
